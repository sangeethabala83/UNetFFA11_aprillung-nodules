def unet_ffa_encoder_with_skips(input_size=(256, 256, 1)):
    inputs = tf.keras.Input(shape=input_size)

    # Encoder with Fractal-Fractional Attention
    e1 = conv_block(inputs, 64)
    att1 = attention_block_with_fractal(e1, 64)
    p1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(att1)

    e2 = conv_block(p1, 128)
    att2 = attention_block_with_fractal(e2, 128)
    p2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(att2)

    e3 = conv_block(p2, 256)
    att3 = attention_block_with_fractal(e3, 256)
    p3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(att3)

    e4 = conv_block(p3, 512)
    att4 = attention_block_with_fractal(e4, 512)

    # Decoder with skip connections
    u5 = tf.keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(att4)
    concat5 = tf.keras.layers.concatenate([u5, att3], axis=3)
    c5 = conv_block(concat5, 256)

    u6 = tf.keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(c5)
    concat6 = tf.keras.layers.concatenate([u6, att2], axis=3)
    c6 = conv_block(concat6, 128)

    u7 = tf.keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(c6)
    concat7 = tf.keras.layers.concatenate([u7, att1], axis=3)
    c7 = conv_block(concat7, 64)

    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c7)

    return tf.keras.Model(inputs=inputs, outputs=outputs)
